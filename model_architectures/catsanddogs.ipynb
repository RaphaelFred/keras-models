{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "#from model_architectures.lenet import lenet\n",
    "#import model_architectures.lenet\n",
    "from lenet import lenet\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"../cats_and_dogs/cats_and_dogs_full/train\"\n",
    "val_dir = \"../cats_and_dogs/cats_and_dogs_full/validation\"\n",
    "test_dir = \"../cats_and_dogs/cats_and_dogs_full/test\"\n",
    "\n",
    "train_images = keras.utils.image_dataset_from_directory(train_dir)\n",
    "val_images = keras.utils.image_dataset_from_directory(val_dir)\n",
    "test_images = keras.utils.image_dataset_from_directory(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = keras.layers.Rescaling(1./255)\n",
    "\n",
    "\n",
    "norm_train_ds = train_images.map(lambda x, y: (normalization_layer(x), y))\n",
    "norm_val_ds = val_images.map(lambda x, y: (normalization_layer(x), y))\n",
    "norm_test_ds = test_images.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = lenet((256, 256, 3), 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 252, 252, 16)      1216      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 252, 252, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 126, 126, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 122, 122, 16)      6416      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 122, 122, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 61, 61, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 59536)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 400)               23814800  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 23,881,566\n",
      "Trainable params: 23,881,566\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FRED031\\.conda\\envs\\tf-gpu2\\lib\\site-packages\\keras\\backend.py:4906: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 52s 72ms/step - loss: 1.5331 - accuracy: 0.4957 - val_loss: 1.0392 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.8801 - accuracy: 0.4961 - val_loss: 0.7860 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.7476 - accuracy: 0.4998 - val_loss: 0.7237 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.7137 - accuracy: 0.5008 - val_loss: 0.7065 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 46s 73ms/step - loss: 0.7029 - accuracy: 0.4991 - val_loss: 0.7001 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 46s 73ms/step - loss: 0.6986 - accuracy: 0.4994 - val_loss: 0.6973 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.6966 - accuracy: 0.4972 - val_loss: 0.6959 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "284/625 [============>.................] - ETA: 24s - loss: 0.6958 - accuracy: 0.5024"
     ]
    }
   ],
   "source": [
    "mod.fit(norm_train_ds, validation_data=norm_val_ds, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.evaluate(norm_test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf-gpu2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b70302f42324619a160c5efe0278680db7114eee763a9989c69f28be2b93177f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
